# Foreground vs Background Segmentation
  

## Introduction  
This repository will contain code and documentation concerning the final project for the course *Signal, Image & Video* taught at **University of Trento**.  

The aim of the project is to develop a "video-conferencing-like" algorithm to segment background and foreground, in order to run an image composition procedure for background substitution. 

Examples of what the output should look like can be found inside the __report_videos__ folder. Each of them refers to the script that holds the same basename, that is:  
- *report_videos/gray.mp4* has been generated by __gray.py__;  
- *report_videos/hsv.mp4* has been generated by __hsv.py__;  
and so on.  


## Installation  
The source code of the project is written in **Python 3.7**.  
Different versions of Python may do just fine, but this cannot be guaranteed.   
It is strongly suggested that you setup a python virtual environment to properly isolate and install the required dependencies. To this aim, we suggest using **Anaconda**. 

### Anaconda Environment  
In order to setup an Anaconda environment with this project dependencies, run the following:  
```
$ conda create --name <your-env-name> python=3.7
$ conda activate <your-env-name>
(<your-env-name>) $ pip install -r requirements.txt  
```  

## What's inside this repo?  
Different proposed techniques are provided within different python files. 
- The default implementation in __gray.py__  uses gray scale frame differencing in order to segment the foreground and the background;  
- An improved implementation can be found in __hsv.py__ , where the HSV colorspace is leveraged in order to take into account the contribution of both brightness and saturation channels to segment the background and the foreground;  
- A customizable implementation in __trackbars.py__ lets users interactively configure proper values for the thresholds related to the saturation and the brightness masks. The default implementation of thresholding in the other scripts is based on Otsu's method.
- A latter script allows to use the __Lukas - Kanade Optical Flow algorithm__ to keep track of the foreground mask over time. This can be found in __optflow.py__.
  

## Run the code  
Each of the scripts comes with a built-in argument parser for customization. In order to have a look at what the different arguments are, simply tipe:  
```
(<your-env-name>) $ python <script-name.py> --help 
```

The output, for every script, will look like the snippet below.

```
usage: <script-name.py> [-h] [-bg BACKGROUND] [-ff FRAME_FOLDER] [-r] [-t THROTTLE] [-ov OUTPUT_VIDEO]

optional arguments:
  -h, --help            show this help message and exit
  -bg BACKGROUND, --background BACKGROUND
                        Path to the image used as background. Default='sample_imgs/catalina-day.jpg'.  
                        If relative, please provide it with respect to the python script you are running.Absolute path is preferred.  
  -ff FRAME_FOLDER, --frame_folder FRAME_FOLDER  
                        Folder where to save processed frames.  
                        No frames will be saved if this argument is not given. It must be relative to the location of the script that you're running.  
  -r, --refresh         Add this flag if you want to delete the content inside 'frame_folder' before saving the frames of this new run.  
  -t THROTTLE, --throttle THROTTLE  
                        Skip int(throttle) frames when saving on disk. Default to 1 (no frames skipped).  
  -ov OUTPUT_VIDEO, --output_video OUTPUT_VIDEO  
                        Path to the output video generated concatenating processed frames. No output video will be generated if this argument is not given. It must be relative to the location of the script that you're running.
```  
A background model is acquired during the first 3 seconds of the video captured via your Webcam, so we suggest staying out of the scene during that interval.  
Each script can be safely exited by pressing *q* on your keyboard.
  
In the __optflow.py__ implementation, moreover, additional actions can be performed while the script is running:  
- the **s** key means "save", so starting from the moment it is pressed, the current visible points of the foreground will be tracked with the Lukas - Kanade algorithm;  
- the **r** key means "reset", so when it is pressed the algorithm re-builds a background model. This is useful for situations when the Optical Flow tracking becomes unstable. After pressing the key, please get out of the scene for 3s.  
  