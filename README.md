# Foreground vs Background Segmentation
  

## Introduction  
This repository contains code and documentation of the final project developed for the course *Signal, Image & Video* taught at **University of Trento**.  

The aim of the project is to develop a "video-conferencing-like" algorithm to segment background and foreground, in order to run an image composition procedure for background substitution. 

Examples of what the output should look like can be found inside the __report_videos__ folder. Each of them refers to the script that holds the same basename, that is:  
- *report_videos/gray.mp4* has been generated by __gray.py__;  
- *report_videos/hsv.mp4* has been generated by __hsv.py__;  
and so on.  


## Installation  
The source code of the project is written in **Python 3.7**.  
Different versions of Python may do just fine, but this cannot be guaranteed.   
It is strongly suggested that you setup a python virtual environment to properly isolate and install the required dependencies. To this aim, we suggest using **Anaconda**. 

### Anaconda Environment  
In order to setup an Anaconda environment with this project dependencies, run the following:  
```
$ conda create --name <your-env-name> python=3.7
$ conda activate <your-env-name>
(<your-env-name>) $ pip install -r requirements.txt  
```  

## What's inside this repo?  
Different proposed techniques are provided within different python files. The report explaining all of them is *siv-report-bg-vs-fg-segmentation_farina-matteo-221252_diprima-federico-224400.pdf*.  
- The default implementation in __gray.py__  uses gray scale frame differencing in order to segment the foreground and the background;  
- An improved implementation can be found in __hsv.py__ , where the HSV colorspace is leveraged in order to take into account the contribution of both brightness and saturation channels to segment the background and the foreground;  
- A customizable implementation in __trackbars.py__ lets users interactively configure proper values for the thresholds related to the saturation and the brightness masks. The default implementation of thresholding in the other scripts is based on Otsu's method.
- A latter script allows to use the __Lucas - Kanade Optical Flow algorithm__ to keep track of the foreground mask over time. This can be found in __optflow.py__.
  

## Run the code  
Each of the scripts comes with a built-in argument parser for customization. In order to have a look at what the different arguments are, simply tipe:  
```
(<your-env-name>) $ python <script-name.py> --help 
```

The output, for every script, will look like the snippet below.

```
usage: <script-name.py> [-h] [-bg BACKGROUND] [-ff FRAME_FOLDER] [-r] [-t THROTTLE] [-ov OUTPUT_VIDEO]

optional arguments:
  -h, --help            show this help message and exit
  -bg BACKGROUND, --background BACKGROUND
                        Path to the image used as background. Default='sample_imgs/catalina-day.jpg'.  
                        If relative, please provide it with respect to the python script you are running.Absolute path is preferred.  
  -ff FRAME_FOLDER, --frame_folder FRAME_FOLDER  
                        Folder where to save processed frames.  
                        No frames will be saved if this argument is not given. It must be relative to the location of the script that you're running.  
  -r, --refresh         Add this flag if you want to delete the content inside 'frame_folder' before saving the frames of this new run.  
  -t THROTTLE, --throttle THROTTLE  
                        Skip int(throttle) frames when saving on disk. Default to 1 (no frames skipped).  
  -ov OUTPUT_VIDEO, --output_video OUTPUT_VIDEO  
                        Path to the output video generated concatenating processed frames. No output video will be generated if this argument is not given. It must be relative to the location of the script that you're running.
```  
In the snippets below, examples are shown in order to launch each of the four scripts mentioned in the introductory section with the command line 
argument to configure the output frame folder as *my_frames* under this project directory:  
1. __Grayscale based background vs foreground segmentation__:  
  ```
  (<your-env-name>) $ python gray.py --frame_folder my_frames
  ```  
2. __HSV based background vs foreground segmentation__:
  ```
  (<your-env-name>) $ python hsv.py --frame_folder my_frames
  ```  
3. __HSV based with trackbars settings__:
  ```
  (<your-env-name>) $ python trackbars.py --frame_folder my_frames
  ```  
4. __HSV based with Lucas-Kanade Optical Flow settings__:
  ```
  (<your-env-name>) $ python optflow.py --frame_folder my_frames
  ```  
  
When a script is running, press the **q** key on your keyboard to exit at any time.  
In the __optflow.py__ implementation, moreover, additional actions can be performed while the script is running:  
- the **s** key means "save", so starting from the moment it is pressed, the current visible points of the foreground will be tracked with the Lukas - Kanade algorithm;  
- the **r** key means "reset", so when it is pressed the algorithm re-builds a background model. This is useful for situations when the Optical Flow tracking becomes unstable. After pressing the key, please get out of the scene for 3s.  
  
### Additional Notes  
A background model is acquired during the first 3 seconds of the video captured by your Webcam. Thus, we suggest staying out of the scene during that interval for better results.  
  
The above snippets showing how to run the scripts are nothing more than pure examples. You can obviously add, tweak or omit any command line argument.  


  
